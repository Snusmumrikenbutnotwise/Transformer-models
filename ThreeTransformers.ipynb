{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nD9tm6vgUBl"
      },
      "source": [
        "##Transformer Architecture (based on GPT-OSS) implementation and testing\n",
        "This notebook was based on task that I have to do for Deep Neural Networks course on University of Warsaw during fall semester of 2025. Because of that not all the code is my, the backbone-structure (based on GPT-OSS 2025) was already implemented. To keep things fair my code in architecture part is comes after ### My Code ### comment. The testing of transformers models was done solely by me. \\\n",
        "\\\n",
        "\\\n",
        "At the first part of this notebook different modules of GPT-OSS-like architecture are implemented. They include:   \n",
        "- SwiGLU module\n",
        "- Grouped Query Attention  \n",
        "- Sliding Window Attention\n",
        "- Rotational Positionary Embedding\n",
        "- Mixture of Experts (without shared expert at this point, maybe I will find time to add it later). \\\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The testing part right now consists of test on three datasets: \\\n",
        "-> CutieSimp model is trained on very simple and easy dataset with simple sentences about two people: 'Cutie' and 'Farfocl' and their relationship. The point here was to get familiar with a very simple text-based example. \\\n",
        "-> TinyStoryTeller model is trained on TinyStories dataset containing short stories. Here tokenization is also implemented. The goal here was to experiment with a bit of a harder task \\\n",
        "-> WieszczMimic model is trained on dataset created from four most important creations of Polish national poet Adam Mickiewicz (*Pan Tadeusz*, *Dziady*, *Konrad Wallenrod* and *GraÅ¼yna*). I wanted to do a fun experiment, although results are not really satisfactory"
      ],
      "metadata": {
        "id": "7h6II6KoKkwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation of the architecture modules\n",
        "----------------------------"
      ],
      "metadata": {
        "id": "z0gmlQNGYgzm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LmNH4Vr2gUBl"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import random\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import IterableDataset, DataLoader\n",
        "from typing import List, Optional, Callable\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import functools\n",
        "import csv\n",
        "import sys\n",
        "\n",
        "#configurations\n",
        "csv.field_size_limit(sys.maxsize);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2mt5ZJIgUBm"
      },
      "source": [
        "### SwiGluFeedForward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Y3rnCEvygUBm"
      },
      "outputs": [],
      "source": [
        "class SwiGLUFeedForward(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim: int, inner_dim: int) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_dim: Dimension of input and output tensors.\n",
        "            inner_dim: Dimension of the intermediate (inner) representation.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        ### My code ###\n",
        "        self.projection1 = torch.nn.Linear(hidden_dim, inner_dim)\n",
        "        self.act = torch.nn.SiLU()\n",
        "        self.projection2 = torch.nn.Linear(hidden_dim, inner_dim)\n",
        "        self.deprojection = torch.nn.Linear(inner_dim, hidden_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape [batch_size, seq_len, hidden_dim].\n",
        "\n",
        "        Returns:\n",
        "            Output tensor of shape [batch_size, seq_len, hidden_dim].\n",
        "        \"\"\"\n",
        "        assert len(x.shape) == 3, f\"Expected 3D tensor, got shape {x.shape}\"\n",
        "\n",
        "        ### My code ###\n",
        "        x_base = self.projection1(x)\n",
        "        x_multiplicative = self.projection2(x)\n",
        "        x_base = self.act(x_base)\n",
        "        x = x_base*x_multiplicative\n",
        "        result = self.deprojection(x)\n",
        "\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCDtN5qHgUBn"
      },
      "source": [
        "### Rotary Positional Embedding (RoPE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RgvR3bjNgUBn"
      },
      "outputs": [],
      "source": [
        "class RotaryPositionalEmbedding(torch.nn.Module):\n",
        "    def __init__(self, head_dim: int, max_seq_len: int = 2048, base: float = 10000.0) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            head_dim: Dimension of each attention head (must be even).\n",
        "            max_seq_len: Maximum sequence length to precompute embeddings for.\n",
        "            base: Base for computing rotation frequencies.\n",
        "\n",
        "        WARNING: YOUR IMPLEMENTATION MUST PRECOMPUTE THE EMBEDDINGS\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        assert head_dim % 2 == 0, \"head_dim must be even for RoPE\"\n",
        "\n",
        "        ### My code ###\n",
        "\n",
        "        self.base = base\n",
        "        self.head_dim = head_dim\n",
        "        self._precompute_cache(max_seq_len)\n",
        "\n",
        "    def _precompute_cache(self, seq_len: int) -> None:\n",
        "\n",
        "        ### My code ###\n",
        "        i_range = torch.arange(0, self.head_dim, 2)\n",
        "        self.theta = torch.pow(self.base, - i_range / self.head_dim)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor, start_pos: int = 0) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape [batch, num_heads, seq_len, head_dim].\n",
        "            start_pos: Starting position index (for KV-cache during inference).\n",
        "\n",
        "        Returns:\n",
        "            Tensor with rotary embedding applied, same shape as input.\n",
        "        \"\"\"\n",
        "\n",
        "        ### My Code ###\n",
        "        batch, num_heads, seq_len, head_dim = x.shape\n",
        "        x_reshaped = x.reshape(-1, seq_len, head_dim)  # Combine batch and num_heads\n",
        "        x_rotated = torch.zeros_like(x_reshaped)\n",
        "        for pos in range(seq_len):\n",
        "            m = pos+start_pos\n",
        "            main_diag = torch.stack((torch.cos(m*self.theta), torch.cos(m*self.theta))).T.flatten()\n",
        "            off_diag = torch.stack((torch.sin(m*self.theta), 0*torch.ones(head_dim // 2))).T.flatten()\n",
        "            mask = torch.ones_like(off_diag, dtype=torch.bool)\n",
        "            mask[-1] = False\n",
        "            off_diag = off_diag[mask]\n",
        "            perm = torch.stack((torch.arange(0, head_dim//2), torch.arange(head_dim//2, head_dim)), dim=1).reshape(-1)\n",
        "            rotmat = torch.diag(main_diag) + torch.diag(-off_diag, diagonal = 1) + torch.diag(off_diag, diagonal = -1)\n",
        "            rotmat = rotmat[:,perm][perm,:].to(x.device)\n",
        "            x_rotated[:, pos, :] = torch.matmul(x_reshaped[:, pos, :], rotmat.T)\n",
        "        x_rotated = x_rotated.reshape(batch, num_heads, seq_len, head_dim)\n",
        "        return x_rotated\n",
        "\n",
        "\n",
        "\n",
        "##### TESTS START #####\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_rope() -> None:\n",
        "    \"\"\"Test RoPE applies correct rotations.\"\"\"\n",
        "    head_dim = 4\n",
        "    max_seq_len = 8\n",
        "    batch, num_heads, seq_len = 2, 2, 4\n",
        "\n",
        "    rope = RotaryPositionalEmbedding(head_dim, max_seq_len)\n",
        "    x = torch.ones(batch, num_heads, seq_len, head_dim)\n",
        "\n",
        "    result = rope(x)\n",
        "\n",
        "    expected = torch.tensor(\n",
        "        [[[[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
        "          [-0.3012,  0.9900,  1.3818,  1.0099],\n",
        "          [-1.3254,  0.9798,  0.4932,  1.0198],\n",
        "          [-1.1311,  0.9696, -0.8489,  1.0295]],\n",
        "\n",
        "         [[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
        "          [-0.3012,  0.9900,  1.3818,  1.0099],\n",
        "          [-1.3254,  0.9798,  0.4932,  1.0198],\n",
        "          [-1.1311,  0.9696, -0.8489,  1.0295]]],\n",
        "\n",
        "\n",
        "        [[[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
        "          [-0.3012,  0.9900,  1.3818,  1.0099],\n",
        "          [-1.3254,  0.9798,  0.4932,  1.0198],\n",
        "          [-1.1311,  0.9696, -0.8489,  1.0295]],\n",
        "\n",
        "         [[ 1.0000,  1.0000,  1.0000,  1.0000],\n",
        "          [-0.3012,  0.9900,  1.3818,  1.0099],\n",
        "          [-1.3254,  0.9798,  0.4932,  1.0198],\n",
        "          [-1.1311,  0.9696, -0.8489,  1.0295]]]]\n",
        "    )\n",
        "\n",
        "    assert result.shape == x.shape, f\"Shape mismatch: {result.shape} vs {x.shape}\"\n",
        "    assert torch.allclose(result, expected, atol=1e-4), \"Error in ROPE\"\n",
        "\n",
        "\n",
        "test_rope()\n",
        "\n",
        "#####  TESTS END  #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blCnnxtigUBn"
      },
      "source": [
        "### Grouped Query Attention (GQA) adn Sliding Window Attention (SWA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vv0pRP0RgUBn"
      },
      "outputs": [],
      "source": [
        "def calculate_attention(\n",
        "    q: torch.Tensor,\n",
        "    k: torch.Tensor,\n",
        "    v: torch.Tensor,\n",
        "    key_weights: torch.Tensor,\n",
        "    rope: RotaryPositionalEmbedding,\n",
        "    scale: float,\n",
        "    device: torch.device,\n",
        "    mask: Optional[torch.Tensor] = None\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        q: Query tensor of shape [batch, num_heads, seq_len, head_dim].\n",
        "        k: Key tensor of shape [batch, num_kv_heads, seq_len, head_dim].\n",
        "        v: Value tensor of shape [batch, num_kv_heads, seq_len, head_dim].\n",
        "        key_weights: Per-head key weights of shape [num_heads].\n",
        "        rope: Rotary positional embedding module.\n",
        "        scale: Scaling factor (typically 1/sqrt(head_dim)).\n",
        "        device: Device to create the causal mask on.\n",
        "        mask: Optional attention mask of shape [seq_len, seq_len]. If None, uses causal mask.\n",
        "\n",
        "    Returns:\n",
        "        Output tensor of shape [batch, num_heads, seq_len, head_dim].\n",
        "    \"\"\"\n",
        "    ### My Code ###\n",
        "    batch, num_heads, seq_len, head_dim = q.size()\n",
        "    num_kv_heads = k.size()[1]\n",
        "    heads_per_kv = num_heads // num_kv_heads\n",
        "    k = rope(k, head_dim)\n",
        "    k = k.repeat_interleave(heads_per_kv, dim=1)    #Needs optimization\n",
        "    v = v.repeat_interleave(heads_per_kv, dim=1)\n",
        "    q = rope(q, head_dim)\n",
        "    k = k * key_weights.view(1, num_heads, 1, 1)\n",
        "    k_t = k.transpose(-1, -2)\n",
        "    attention = torch.matmul(q, k_t) * scale\n",
        "    if mask == None:\n",
        "      mask = torch.triu(torch.full((seq_len, seq_len), -1e9, device=device, dtype=q.dtype), diagonal=1)\n",
        "      mask = mask.unsqueeze(0).unsqueeze(0)  # broadcast to [1,1,seq_len,seq_len]\n",
        "    attention = attention + mask\n",
        "    attention_weights = F.softmax(attention, dim=-1)\n",
        "    O = torch.matmul(attention_weights, v)\n",
        "    output = O\n",
        "    return output\n",
        "\n",
        "\n",
        "class GroupedQueryAttention(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_dim: int,\n",
        "        num_heads: int,\n",
        "        head_dim: int,\n",
        "        num_kv_heads: Optional[int] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_dim: Input/output dimension.\n",
        "            num_heads: Number of query heads.\n",
        "            head_dim: Dimension of each head.\n",
        "            num_kv_heads: Number of key-value heads. If None, defaults to num_heads (standard MHA).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = head_dim\n",
        "        self.num_kv_heads = num_kv_heads if num_kv_heads is not None else num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "\n",
        "        assert num_heads % self.num_kv_heads == 0, \"num_heads must be divisible by num_kv_heads\"\n",
        "        self.num_queries_per_kv = num_heads // self.num_kv_heads\n",
        "\n",
        "        ### My code ###\n",
        "        self.key_weights = torch.nn.Parameter(torch.ones(num_heads))\n",
        "        self.kmat = torch.nn.Linear(self.hidden_dim, self.num_kv_heads*self.head_dim)\n",
        "        self.vmat = torch.nn.Linear(self.hidden_dim, self.num_kv_heads*self.head_dim)\n",
        "        self.qmat = torch.nn.Linear(self.hidden_dim, self.num_heads*self.head_dim)\n",
        "        self.outmat = torch.nn.Linear( self.num_heads * self.head_dim, self.hidden_dim)\n",
        "        self.rope = RotaryPositionalEmbedding(self.head_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape [batch, seq_len, hidden_dim].\n",
        "\n",
        "        Returns:\n",
        "            Output tensor of shape [batch, seq_len, hidden_dim].\n",
        "        \"\"\"\n",
        "        assert len(x.shape) == 3\n",
        "        batch, seq_len, _ = x.shape\n",
        "\n",
        "        ### My Code ###\n",
        "        k = self.kmat(x)\n",
        "        k = k.reshape(batch, seq_len, self.num_kv_heads, self.head_dim)\n",
        "        k = k.transpose(-2, -3)\n",
        "\n",
        "        v = self.vmat(x)\n",
        "        v = v.reshape(batch, seq_len, self.num_kv_heads, self.head_dim)\n",
        "        v = v.transpose(-2, -3)\n",
        "\n",
        "        q = self.qmat(x)\n",
        "        q = q.reshape(batch, seq_len, self.num_heads, self.head_dim)\n",
        "        q = q.transpose(-2, -3)\n",
        "\n",
        "        O = calculate_attention(q, k, v, self.key_weights, self.rope, self.scale, q.device)\n",
        "        O = O.transpose(-2, -3).reshape(batch, seq_len, self.num_heads * self.head_dim)\n",
        "        output = self.outmat(O)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "fjkoUm31gUBo"
      },
      "outputs": [],
      "source": [
        "def calculate_sliding_attention(\n",
        "    q: torch.Tensor,\n",
        "    k: torch.Tensor,\n",
        "    v: torch.Tensor,\n",
        "    key_weights: torch.Tensor,\n",
        "    rope: RotaryPositionalEmbedding,\n",
        "    scale: float,\n",
        "    device: torch.device,\n",
        "    window_size: int\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        q: Query tensor of shape [batch, num_heads, seq_len, head_dim].\n",
        "        k: Key tensor of shape [batch, num_kv_heads, seq_len, head_dim].\n",
        "        v: Value tensor of shape [batch, num_kv_heads, seq_len, head_dim].\n",
        "        key_weights: Per-head key weights of shape [num_heads].\n",
        "        rope: Rotary positional embedding module.\n",
        "        scale: Scaling factor (typically 1/sqrt(head_dim)).\n",
        "        device: Device to create the causal mask on.\n",
        "        window_size: Number of previous tokens each position can attend to.\n",
        "\n",
        "    Returns:\n",
        "        Output tensor of shape [batch, num_heads, seq_len, head_dim].\n",
        "    \"\"\"\n",
        "    _, __, seq_len, ___ = q.size()\n",
        "    mask = torch.triu(torch.full((seq_len, seq_len), -1e9, device=device, dtype=q.dtype), diagonal=1) + torch.tril(torch.full((seq_len, seq_len), -1e9, device=device, dtype=q.dtype), diagonal=-window_size-1)\n",
        "    mask = mask.unsqueeze(0).unsqueeze(0)  # broadcast to [1,1,seq_len,seq_len]\n",
        "    output = calculate_attention(q, k, v, key_weights, rope, scale, device, mask = mask)\n",
        "    return output\n",
        "\n",
        "\n",
        "class SWAttention(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_dim: int,\n",
        "        num_heads: int,\n",
        "        head_dim: int,\n",
        "        window_size: int\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_dim: Input/output dimension.\n",
        "            num_heads: Number of attention heads.\n",
        "            head_dim: Dimension of each head.\n",
        "            window_size: Size of the sliding window.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = head_dim\n",
        "        self.window_size = window_size\n",
        "        self.scale = head_dim ** -0.5\n",
        "\n",
        "        ### My code ###\n",
        "        self.key_weights = torch.nn.Parameter(torch.ones(num_heads))\n",
        "        self.kmat = torch.nn.Linear(self.hidden_dim, self.num_heads*self.head_dim)\n",
        "        self.vmat = torch.nn.Linear(self.hidden_dim, self.num_heads*self.head_dim)\n",
        "        self.qmat = torch.nn.Linear(self.hidden_dim, self.num_heads*self.head_dim)\n",
        "        self.outmat = torch.nn.Linear( self.num_heads * self.head_dim, self.hidden_dim)\n",
        "        self.rope = RotaryPositionalEmbedding(self.head_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape [batch, seq_len, hidden_dim].\n",
        "\n",
        "        Returns:\n",
        "            Output tensor of shape [batch, seq_len, hidden_dim].\n",
        "        \"\"\"\n",
        "        assert len(x.shape) == 3\n",
        "        batch, seq_len, _ = x.shape\n",
        "\n",
        "        ### My Code ###\n",
        "        k = self.kmat(x)\n",
        "        k = k.reshape(batch, seq_len, self.num_heads, self.head_dim)\n",
        "        k = k.transpose(-2, -3)  #check dimensions\n",
        "\n",
        "        v = self.vmat(x)\n",
        "        v = v.reshape(batch, seq_len, self.num_heads, self.head_dim)\n",
        "        v = v.transpose(-2, -3)\n",
        "\n",
        "        q = self.qmat(x)\n",
        "        q = q.reshape(batch, seq_len, self.num_heads, self.head_dim)\n",
        "        q = q.transpose(-2, -3)\n",
        "\n",
        "        O = calculate_sliding_attention(q, k, v, self.key_weights, self.rope, self.scale, q.device, self.window_size)\n",
        "        O = O.transpose(-2, -3).reshape(batch, seq_len, self.num_heads * self.head_dim)\n",
        "        output = self.outmat(O)\n",
        "        return output\n",
        "\n",
        "\n",
        "##### TESTS START #####\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_calculate_sliding_attention() -> None:\n",
        "    \"\"\"Test the calculate_sliding_attention function independently of module weights.\"\"\"\n",
        "    torch.manual_seed(42)\n",
        "    batch, seq_len = 2, 4\n",
        "    num_heads, head_dim = 4, 4\n",
        "    window_size = 2\n",
        "\n",
        "    q = torch.randn(batch, num_heads, seq_len, head_dim)\n",
        "    k = torch.randn(batch, num_heads, seq_len, head_dim)\n",
        "    v = torch.randn(batch, num_heads, seq_len, head_dim)\n",
        "\n",
        "    key_weights = torch.randn(num_heads)\n",
        "    rope = RotaryPositionalEmbedding(head_dim)\n",
        "    scale = head_dim ** -0.5\n",
        "\n",
        "    output = calculate_sliding_attention(q, k, v, key_weights, rope, scale, q.device, window_size)\n",
        "\n",
        "    assert output.shape == (batch, num_heads, seq_len, head_dim), \\\n",
        "        f\"Wrong output shape: {output.shape}, expected {(batch, num_heads, seq_len, head_dim)}\"\n",
        "\n",
        "    expected = torch.tensor(\n",
        "        [[[[-6.8548e-01,  5.6356e-01, -1.5072e+00, -1.6107e+00],\n",
        "          [-7.5833e-01,  5.5151e-01, -1.3803e+00, -1.3910e+00],\n",
        "          [-7.5970e-01,  5.4425e-01, -1.3694e+00, -1.4018e+00],\n",
        "          [-1.0289e+00, -1.5047e-03,  1.3449e-01,  8.8395e-02]],\n",
        "\n",
        "         [[-1.3793e+00,  6.2580e-01, -2.5850e+00, -2.4000e-02],\n",
        "          [-1.0804e+00,  2.9937e-01, -1.5638e+00, -4.5193e-03],\n",
        "          [-3.7572e-01,  9.0874e-01, -9.8827e-01,  3.2158e-01],\n",
        "          [ 5.5610e-01,  9.3138e-01,  8.2518e-01,  3.6249e-01]],\n",
        "\n",
        "         [[ 9.7329e-01, -1.0151e+00, -5.4192e-01, -4.4102e-01],\n",
        "          [ 3.7820e-01, -6.0546e-01, -6.2194e-01, -2.5908e-01],\n",
        "          [ 7.5603e-01, -4.5413e-01, -2.9462e-01, -6.9975e-02],\n",
        "          [ 5.6501e-01,  6.4487e-02,  4.0517e-01,  4.1787e-01]],\n",
        "\n",
        "         [[ 4.0380e-01, -7.1398e-01,  8.3373e-01, -9.5855e-01],\n",
        "          [ 4.2490e-01,  1.1594e-01, -4.9589e-01, -1.0976e+00],\n",
        "          [ 3.5349e-01, -4.0529e-01, -6.6044e-01, -1.1089e+00],\n",
        "          [-2.1912e-01, -6.5963e-01,  1.6555e-01, -1.0503e+00]]],\n",
        "\n",
        "\n",
        "        [[[ 4.3344e-01, -7.1719e-01,  1.0554e+00, -1.4534e+00],\n",
        "          [ 4.4607e-01, -2.8344e-01,  6.3300e-01, -8.4259e-01],\n",
        "          [ 4.2691e-01,  3.2082e-01, -4.8548e-01, -5.2133e-01],\n",
        "          [ 3.8897e-01,  6.5369e-01, -1.5100e+00, -7.1436e-01]],\n",
        "\n",
        "         [[ 8.8538e-01,  1.8244e-01,  7.8638e-01, -5.7920e-02],\n",
        "          [ 7.1542e-01, -2.9334e-01,  1.0705e-01, -3.1831e-04],\n",
        "          [ 6.7078e-01,  7.1021e-01,  4.8379e-02,  5.4688e-01],\n",
        "          [ 7.3988e-01,  2.3339e-01, -3.6269e-01,  3.0450e-01]],\n",
        "\n",
        "         [[-7.9394e-01,  3.7523e-01,  8.7910e-02, -1.2415e+00],\n",
        "          [-5.1264e-01, -3.4904e-01, -2.9172e-01,  6.7694e-01],\n",
        "          [ 4.9596e-01,  5.8218e-01, -1.2478e-01,  1.5970e-01],\n",
        "          [ 6.7310e-02,  1.5020e-01, -2.8622e-01,  1.1465e+00]],\n",
        "\n",
        "         [[-2.1844e-01,  1.6630e-01,  2.1442e+00,  1.7046e+00],\n",
        "          [ 9.8019e-02,  4.3332e-01,  8.2743e-01,  1.1330e+00],\n",
        "          [ 2.0074e-02, -5.5385e-02,  2.2436e-01,  9.4053e-01],\n",
        "          [-1.2419e-01,  1.2867e-01, -6.4606e-01,  2.5874e-01]]]]\n",
        "    )\n",
        "\n",
        "    assert torch.allclose(output, expected, atol=1e-4), \\\n",
        "        f\"calculate_sliding_attention output values mismatch\"\n",
        "\n",
        "test_calculate_sliding_attention()\n",
        "\n",
        "#####  TESTS END  #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AOdAri4gUBo"
      },
      "source": [
        "### Mixture of Experts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_XPPWV5bgUBo"
      },
      "outputs": [],
      "source": [
        "class Router(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim: int, num_experts: int, top_k: int = 2) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_dim: Input dimension.\n",
        "            num_experts: Total number of experts.\n",
        "            top_k: Number of experts to activate per token.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_experts = num_experts\n",
        "        self.top_k = top_k\n",
        "\n",
        "        ### My Code ###\n",
        "        self.linearity = torch.nn.Linear(hidden_dim, num_experts)\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape [batch, seq_len, hidden_dim].\n",
        "\n",
        "        Returns:\n",
        "            routing_weights: Tensor of shape [batch, seq_len, top_k] with softmax weights.\n",
        "            expert_indices: Tensor of shape [batch, seq_len, top_k] with selected expert indices.\n",
        "        \"\"\"\n",
        "        assert len(x.shape) == 3\n",
        "\n",
        "        ### My code ###\n",
        "        w = self.linearity(x)\n",
        "        expert_indices = w.argsort(dim=-1, descending=True)[:self.top_k]\n",
        "        topk_scores = torch.gather(w, -1, expert_indices)  # shape: [batch, seq_len, top_k]\n",
        "        routing_weights = F.softmax(topk_scores, dim=-1)\n",
        "\n",
        "        return routing_weights, expert_indices\n",
        "\n",
        "\n",
        "class MixtureOfExperts(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_dim: int,\n",
        "        inner_dim: int,\n",
        "        num_experts: int = 8,\n",
        "        top_k: int = 2\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_dim: Input/output dimension.\n",
        "            inner_dim: Inner dimension of each expert.\n",
        "            num_experts: Total number of experts.\n",
        "            top_k: Number of experts to activate per token.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_experts = num_experts\n",
        "        self.top_k = top_k\n",
        "\n",
        "        ### My code ###\n",
        "        self.inner_dim = inner_dim\n",
        "        self.experts = torch.nn.ModuleList([SwiGLUFeedForward(self.hidden_dim, self.inner_dim) for i in range(num_experts)])\n",
        "        self.router = Router(self.hidden_dim, self.num_experts, self.top_k)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape [batch, seq_len, hidden_dim].\n",
        "\n",
        "        Returns:\n",
        "            Output tensor of shape [batch, seq_len, hidden_dim].\n",
        "        \"\"\"\n",
        "        assert len(x.shape) == 3\n",
        "        batch, seq_len, hidden_dim = x.shape\n",
        "\n",
        "        ### My code ###\n",
        "        routing_weights, expert_indices = self.router(x)\n",
        "        experts_outputs = torch.stack([expert(x) for expert in self.experts], dim=0)\n",
        "        indices = expert_indices.unsqueeze(-1).expand(-1, -1, -1, hidden_dim)  # [batch, seq_len, top_k, hidden_dim]\n",
        "        experts_outputs = experts_outputs.permute(1, 2, 0, 3)  # [batch, seq_len, num_experts, hidden_dim]\n",
        "\n",
        "        # Gather top-k outputs\n",
        "        topk_outputs = torch.gather(experts_outputs, 2, indices)  # [batch, seq_len, top_k, hidden_dim]\n",
        "        routing_weights = routing_weights.unsqueeze(-1)  # [batch, seq_len, top_k, 1]\n",
        "        weighted_outputs = topk_outputs * routing_weights  # [batch, seq_len, top_k, hidden_dim]\n",
        "\n",
        "        # Sum over top-k\n",
        "        output = weighted_outputs.sum(dim=2)  # [batch, seq_len, hidden_dim]\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7tjKtgAgUBo"
      },
      "source": [
        "###Transformer Block\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9LXCPLuAgUBo"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        hidden_dim: int,\n",
        "        ff_dim: int,\n",
        "        num_heads: int,\n",
        "        head_dim: int,\n",
        "        use_sliding_window: bool = False,\n",
        "        window_size: int = 128,\n",
        "        use_moe: bool = False,\n",
        "        num_experts: int = 8,\n",
        "        top_k: int = 2,\n",
        "        num_kv_heads: Optional[int] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            hidden_dim: Hidden dimension.\n",
        "            ff_dim: Feed-forward inner dimension.\n",
        "            num_heads: Number of attention heads.\n",
        "            head_dim: Dimension per attention head.\n",
        "            use_sliding_window: Whether to use sliding window attention.\n",
        "            window_size: Size of sliding window (if used).\n",
        "            use_moe: Whether to use Mixture of Experts instead of single FFN.\n",
        "            num_experts: Number of experts (if MoE).\n",
        "            top_k: Number of experts per token (if MoE).\n",
        "            num_kv_heads: Number of KV heads for GQA (None = standard MHA).\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.ff_dim = ff_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = head_dim\n",
        "\n",
        "        ### My code ###\n",
        "        if use_sliding_window:\n",
        "          self.use_sliding_window = use_sliding_window\n",
        "          self.window_size = window_size\n",
        "          self.attention = SWAttention(self.hidden_dim, self.num_heads, self.head_dim, self.window_size)\n",
        "        else:\n",
        "          self.num_kv_heads = num_kv_heads\n",
        "          self.attention = GroupedQueryAttention(self.hidden_dim, self.num_heads, self.head_dim, self.num_kv_heads)\n",
        "\n",
        "        if use_moe:\n",
        "          self.use_moe = use_moe\n",
        "          self.num_experts = num_experts\n",
        "          self.top_k = top_k\n",
        "          self.forward_layer = MixtureOfExperts(self.hidden_dim, self.ff_dim, self.num_experts, self.top_k)\n",
        "        else:\n",
        "          self.forward_layer = SwiGLUFeedForward(self.hidden_dim, self.ff_dim)\n",
        "\n",
        "        self.norm1 = torch.nn.RMSNorm(hidden_dim)\n",
        "        self.norm2 = torch.nn.RMSNorm(hidden_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape [batch, seq_len, hidden_dim].\n",
        "\n",
        "        Returns:\n",
        "            Output tensor of shape [batch, seq_len, hidden_dim].\n",
        "        \"\"\"\n",
        "        ### My code ###\n",
        "        r = self.norm1(x)\n",
        "        r = r + self.attention(r)\n",
        "        r = self.norm2(r)\n",
        "        result = r + self.forward_layer(r)\n",
        "\n",
        "        assert x.shape == result.shape\n",
        "        return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eghb_YpPgUBp"
      },
      "source": [
        "### The Transfomer model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xuxKQfX9gUBp"
      },
      "outputs": [],
      "source": [
        "class Transformer(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        n_layers: int,\n",
        "        hidden_dim: int,\n",
        "        ff_dim: int,\n",
        "        num_heads: int,\n",
        "        head_dim: int,\n",
        "        use_sliding_window_alternating: bool = False,\n",
        "        window_size: int = 128,\n",
        "        use_moe: bool = False,\n",
        "        num_experts: int = 8,\n",
        "        top_k: int = 2,\n",
        "        num_kv_heads: Optional[int] = None\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            vocab_size: Size of the vocabulary.\n",
        "            n_layers: Number of transformer layers.\n",
        "            hidden_dim: Hidden dimension.\n",
        "            ff_dim: Feed-forward inner dimension.\n",
        "            num_heads: Number of attention heads.\n",
        "            head_dim: Dimension per attention head.\n",
        "            use_sliding_window_alternating: Use sliding window on every other layer\n",
        "            window_size: Size of sliding window.\n",
        "            use_moe: Whether to use Mixture of Experts.\n",
        "            num_experts: Number of experts (if MoE).\n",
        "            top_k: Number of experts per token (if MoE).\n",
        "            num_kv_heads: Number of KV heads for GQA.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab_size = vocab_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.ff_dim = ff_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = head_dim\n",
        "\n",
        "        ### My code ###\n",
        "        self.embedding = torch.nn.Embedding(self.vocab_size, self.hidden_dim)\n",
        "        self.output_proj = torch.nn.Linear(self.hidden_dim, self.vocab_size)\n",
        "        self.final_norm = torch.nn.RMSNorm(hidden_dim)\n",
        "        if use_sliding_window_alternating:\n",
        "          dummy = [False, True]\n",
        "          self.layers = torch.nn.Sequential(*[TransformerBlock(self.hidden_dim, self.ff_dim, self.num_heads, self.head_dim, dummy[i%2], window_size, use_moe, num_experts, top_k, num_kv_heads) for i in range(n_layers)])\n",
        "        else:\n",
        "          self.layers = torch.nn.Sequential(*[TransformerBlock(self.hidden_dim, self.ff_dim, self.num_heads, self.head_dim, False, use_moe=use_moe, num_kv_heads = num_kv_heads) for i in range(n_layers)])\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Token indices of shape [batch, seq_len].\n",
        "\n",
        "        Returns:\n",
        "            Logits of shape [batch, seq_len, vocab_size].\n",
        "        \"\"\"\n",
        "        assert len(x.shape) == 2, f\"Expected 2D input, got shape {x.shape}\"\n",
        "\n",
        "        ### My code ###\n",
        "\n",
        "        r = self.embedding(x)\n",
        "        r = self.layers(r)\n",
        "        r = self.final_norm(r)\n",
        "        logits = self.output_proj(r)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWG9TdEMgUBp"
      },
      "source": [
        "\n",
        "## First Dataset - Cutie&Farfocl  ##\n",
        "----------------------------\n",
        "Small version of this transformer architecture will learn simple text patterns from 'Cutie&Farfocl' dataset. It consists of repetitive sentences from vocabulary of around 70 words\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"CutieAndFarfocl.csv\", \"r\", encoding=\"utf-8\") as f:\n",
        "    reader = csv.reader(f)\n",
        "    text = next(reader)[0]\n",
        "print(text[160:206])\n",
        "print(text[255:308])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB_6rSTwy_J2",
        "outputId": "6954572f-e857-4ec1-f2c9-d5c0e632f35c",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Despite Farfocl being big Cutie loves Farfocl \n",
            "Cutie is not only really cute but also really smart .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data pipeline ###"
      ],
      "metadata": {
        "id": "eh3imyNiz--N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextDataset:\n",
        "    def __init__(self, text: str):\n",
        "        # Tokenize by spaces\n",
        "        self.tokens: List[str] = text.split(\" \")\n",
        "        self.cnt = Counter(self.tokens)\n",
        "\n",
        "        # Vocabulary\n",
        "        self.vocab = sorted(set(self.tokens))\n",
        "        self.vocab_size = len(self.vocab)\n",
        "\n",
        "        self.stoi = {tok: i for i, tok in enumerate(self.vocab)}\n",
        "        self.itos = {i: tok for tok, i in self.stoi.items()}\n",
        "\n",
        "        # Encode entire text as indices\n",
        "        self.data = torch.tensor(\n",
        "            [self.stoi[t] for t in self.tokens],\n",
        "            dtype=torch.long\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "class RandomBatchGenerator:\n",
        "    def __init__(self, dataset: TextDataset, seq_len: int, batch_size: int, device=\"cpu\"):\n",
        "        self.dataset = dataset\n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "\n",
        "    def sample(self):\n",
        "        data = self.dataset.data\n",
        "        vocab_size = self.dataset.vocab_size\n",
        "\n",
        "        max_start = len(data) - self.seq_len - 1\n",
        "        starts = torch.randint(0, max_start, (self.batch_size,))\n",
        "\n",
        "        x_idx = torch.stack([\n",
        "            data[s : s + self.seq_len] for s in starts\n",
        "        ])\n",
        "\n",
        "        y = torch.stack([\n",
        "            data[s + 1 : s + self.seq_len + 1] for s in starts\n",
        "        ])\n",
        "\n",
        "        # One-hot embedding\n",
        "        x = torch.nn.functional.one_hot(\n",
        "            x_idx, num_classes=vocab_size\n",
        "        ).float()\n",
        "\n",
        "        return x.to(self.device), y.to(self.device)\n"
      ],
      "metadata": {
        "id": "7UXUg7XhGioa"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomTextDataset(IterableDataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        \"\"\"\n",
        "        data: 1D LongTensor of token IDs\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __iter__(self):\n",
        "        data = self.data\n",
        "        L = self.seq_len\n",
        "        max_start = len(data) - L - 1\n",
        "\n",
        "        while True:\n",
        "            s = torch.randint(0, max_start, (1,)).item()\n",
        "\n",
        "            x = data[s : s + L]           # [seq_len]\n",
        "            y = data[s + 1 : s + L + 1]   # [seq_len]\n",
        "\n",
        "            yield x, y\n",
        "\n",
        "\n",
        "\n",
        "def decode(indices, itos):\n",
        "    \"\"\"\n",
        "    indices: 1D or 2D tensor of token IDs\n",
        "    itos: dict mapping index -> token (from TextDataset)\n",
        "    \"\"\"\n",
        "    # ensure CPU\n",
        "    indices = indices.cpu()\n",
        "\n",
        "    # if 2D batch, pick first sequence\n",
        "    if indices.dim() == 2:\n",
        "        indices = indices[0]\n",
        "\n",
        "    # map each token ID -> string\n",
        "    decoded = \" \".join(itos[i.item()] for i in indices)\n",
        "\n",
        "    # find all occurrences of '.'\n",
        "    dots = [i for i, char in enumerate(decoded) if char == '.']\n",
        "\n",
        "    if not dots:\n",
        "        return decoded\n",
        "\n",
        "    # discard everything after last '.'\n",
        "    last_dot = dots[-1]\n",
        "    decoded = decoded[:last_dot + 1]\n",
        "\n",
        "    # add newline after every '.' except the last one\n",
        "    result = []\n",
        "    prev = 0\n",
        "    for dot in dots[:-1]:\n",
        "        result.append(decoded[prev:dot + 1])\n",
        "        prev = dot + 1\n",
        "    result.append(decoded[prev:])\n",
        "\n",
        "    return \"\\n\".join(result)\n",
        "\n",
        "\n",
        "def split_data(data, split_ratio=0.9):\n",
        "    n = int(len(data) * split_ratio)\n",
        "    return data[:n], data[n:]\n"
      ],
      "metadata": {
        "id": "MgaWdp7iIWrw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TextDataset(text)\n",
        "train_data, val_data = split_data(dataset.data)\n",
        "\n",
        "seq_len = 32\n",
        "batch_size = 64\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_ds = RandomTextDataset(\n",
        "    train_data,\n",
        "    seq_len=seq_len,\n",
        ")\n",
        "\n",
        "val_ds = RandomTextDataset(\n",
        "    val_data,\n",
        "    seq_len=seq_len,\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "uM9fuDfdJeoL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Vocabulary')\n",
        "print('Index: word: counts')\n",
        "for i, item in enumerate(dataset.vocab):\n",
        "  print(str(i) + ': ' + item + ': ' + str(dataset.cnt[item]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWQuy3VjiKVw",
        "outputId": "bb925efe-53d1-434e-a783-03288d9eeb50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary\n",
            "Index: word: counts\n",
            "0: : 641\n",
            "1: .: 23946\n",
            "2: 22: 73\n",
            "3: Cutie: 17931\n",
            "4: Despite: 630\n",
            "5: Farfocl: 15008\n",
            "6: Not: 648\n",
            "7: On: 4632\n",
            "8: The: 504\n",
            "9: Warsaw: 77\n",
            "10: a: 800\n",
            "11: about: 126\n",
            "12: adores: 126\n",
            "13: also: 7596\n",
            "14: always: 160\n",
            "15: and: 3156\n",
            "16: are: 2484\n",
            "17: attracted: 73\n",
            "18: being: 882\n",
            "19: big: 1407\n",
            "20: but: 12228\n",
            "21: cares: 126\n",
            "22: clumsy: 1406\n",
            "23: couple: 480\n",
            "24: crazy: 1406\n",
            "25: creative: 2122\n",
            "26: cute: 2122\n",
            "27: despite: 252\n",
            "28: dumb: 1406\n",
            "29: extremely: 4283\n",
            "30: for: 320\n",
            "31: freaky: 480\n",
            "32: funny: 2122\n",
            "33: hand: 4952\n",
            "34: his: 219\n",
            "35: hot: 3688\n",
            "36: impressive: 1\n",
            "37: impressively: 3963\n",
            "38: in: 786\n",
            "39: inseparable: 320\n",
            "40: inspiration: 73\n",
            "41: interesting: 2122\n",
            "42: is: 27487\n",
            "43: living: 73\n",
            "44: love: 626\n",
            "45: lovely: 2442\n",
            "46: lovers: 160\n",
            "47: loves: 126\n",
            "48: merely: 5323\n",
            "49: muse: 73\n",
            "50: not: 12272\n",
            "51: of: 252\n",
            "52: often: 160\n",
            "53: old.: 73\n",
            "54: only: 7596\n",
            "55: other: 4632\n",
            "56: pair: 320\n",
            "57: petite: 2122\n",
            "58: pretty: 2123\n",
            "59: really: 3963\n",
            "60: sexy: 2282\n",
            "61: slow: 1406\n",
            "62: small: 2123\n",
            "63: smart: 2122\n",
            "64: strong: 1406\n",
            "65: surely: 4123\n",
            "66: the: 4632\n",
            "67: they: 648\n",
            "68: three: 320\n",
            "69: to: 73\n",
            "70: together: 892\n",
            "71: very: 11889\n",
            "72: wholesome: 2282\n",
            "73: with: 73\n",
            "74: years: 393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVCd6Wi0gUBq"
      },
      "source": [
        "### Training and Evaluation functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pLlSYPoogUBq"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad\n",
        "def eval_acc(model: torch.nn.Module, dataloader: torch.utils.data.DataLoader):\n",
        "    model.eval()\n",
        "    sum_acc = 0\n",
        "    num_examples = 0\n",
        "    for step, (x, y) in enumerate(dataloader):\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "        model_out = model(x)\n",
        "\n",
        "        # Transpose model_out to match expected input for cross_entropy: [batch_size, vocab_size, seq_len]\n",
        "        acc = (torch.argmax(model_out, dim=-1) == y).to(torch.float32).sum()\n",
        "        sum_acc += acc\n",
        "        num_examples += model_out.shape[0] * model_out.shape[1]\n",
        "\n",
        "        if step > 10:\n",
        "          break\n",
        "\n",
        "    return sum_acc / num_examples\n",
        "\n",
        "\n",
        "def eval_fn(step, model, dataloader):\n",
        "    acc = eval_acc(model, dataloader)\n",
        "    print(f\"{step}: Avg eval accuracy {acc}\")\n",
        "\n",
        "\n",
        "def train(\n",
        "    model: torch.nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    dataloader: torch.utils.data.DataLoader,\n",
        "    eval_fn: functools.partial,\n",
        "    num_epochs: int,\n",
        "    scheduler,\n",
        "):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch == 0:\n",
        "            eval_fn(epoch, model)\n",
        "\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "        for i, (x, y) in tqdm(enumerate(dataloader)):\n",
        "            ### My code ###\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            model_out = model(x)\n",
        "            loss = torch.nn.functional.cross_entropy(model_out.transpose(1, 2), y)\n",
        "            #loss = torch.nn.functional.cross_entropy(model_out.transpose(1, 2), y, ignore_index=tokenizer.pad_token_id)  # <- ignore padding\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            if i > 100:\n",
        "                break\n",
        "\n",
        "        eval_fn(epoch, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model definition ###\n",
        "\n"
      ],
      "metadata": {
        "id": "qYm1EqtW1OUk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CutieSimp = Transformer(\n",
        "    vocab_size=dataset.vocab_size, n_layers=4, hidden_dim=128, ff_dim=256, num_heads=4, head_dim=32\n",
        ")"
      ],
      "metadata": {
        "id": "YwQvqg3N0WQ2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training ###"
      ],
      "metadata": {
        "id": "ngLc4ipm1fg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "CutieSimp.to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(CutieSimp.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs  = 12\n",
        "\n",
        "scheduler = CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=100 * num_epochs\n",
        ")\n",
        "\n",
        "train(\n",
        "    model=CutieSimp,\n",
        "    optimizer=optimizer,\n",
        "    dataloader=train_loader,\n",
        "    eval_fn=functools.partial(\n",
        "        eval_fn,\n",
        "        dataloader=val_loader,\n",
        "    ),\n",
        "    num_epochs=num_epochs, scheduler=scheduler\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMMrnEje1f_j",
        "outputId": "77399a4e-6eb0-446b-aa6e-11d92210b99d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Avg eval accuracy 0.013102213852107525\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:16,  5.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Avg eval accuracy 0.6468505859375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:18,  5.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Avg eval accuracy 0.6560465693473816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:18,  5.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2: Avg eval accuracy 0.6569010615348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:17,  5.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3: Avg eval accuracy 0.6571859121322632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:18,  5.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4: Avg eval accuracy 0.6582438349723816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:16,  6.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5: Avg eval accuracy 0.6540120840072632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:14,  6.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6: Avg eval accuracy 0.6603597402572632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:14,  6.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7: Avg eval accuracy 0.6533610224723816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:16,  6.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8: Avg eval accuracy 0.6539306640625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:15,  6.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9: Avg eval accuracy 0.6576334834098816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:15,  6.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10: Avg eval accuracy 0.6569010615348816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [00:17,  5.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11: Avg eval accuracy 0.65576171875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1SB2DRlgUBr"
      },
      "source": [
        "### Sampling functions ###\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Rg4Bi45ZgUBr"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def token_choice_greedy(model_logits: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Select the most likely token (greedy decoding).\n",
        "\n",
        "    Args:\n",
        "        model_logits: Logits of shape [batch, seq_len, vocab_size].\n",
        "\n",
        "    Returns:\n",
        "        Selected token indices of shape [batch, 1].\n",
        "    \"\"\"\n",
        "    assert len(model_logits.shape) == 3\n",
        "    return torch.argmax(model_logits[:, -1:, :], dim=-1)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate(\n",
        "    model: torch.nn.Module,\n",
        "    input: torch.Tensor,\n",
        "    gen_length: int,\n",
        "    token_choice: Callable[[torch.Tensor], torch.Tensor] = token_choice_greedy\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Generate new tokens autoregressively.\n",
        "\n",
        "    Args:\n",
        "        model: The transformer model.\n",
        "        input: Initial token sequence of shape [batch, seq_len].\n",
        "        gen_length: Number of tokens to generate.\n",
        "        token_choice: Function to select next token from logits.\n",
        "\n",
        "    Returns:\n",
        "        Generated tokens of shape [batch, gen_length] (without the input).\n",
        "    \"\"\"\n",
        "    assert len(input.shape) == 2\n",
        "    model.eval()\n",
        "\n",
        "    current_seq = input.to(DEVICE)\n",
        "    output_tokens = []\n",
        "\n",
        "    for _ in range(gen_length):\n",
        "        ### My code ###\n",
        "        model_out = model(current_seq)\n",
        "        next_token = token_choice(model_out)\n",
        "        output_tokens.append(next_token)\n",
        "        current_seq = torch.cat([current_seq, next_token], dim=-1)\n",
        "\n",
        "    return torch.cat(output_tokens, dim=-1)\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_dist_after_with_temp_and_topp(\n",
        "    model_logits: torch.Tensor, top_p: float, t: float\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Apply temperature scaling and top-p (nucleus) sampling.\n",
        "\n",
        "    Args:\n",
        "        model_logits: Logits of shape [batch, seq_len, vocab_size].\n",
        "        top_p: Cumulative probability threshold for nucleus sampling.\n",
        "               0.0 = greedy (only most probable token)\n",
        "               1.0 = full distribution\n",
        "        t: Temperature for softmax. Higher = more uniform, lower = more peaked.\n",
        "\n",
        "    Returns:\n",
        "        Probability distribution of shape [batch, seq_len, vocab_size] with\n",
        "        low-probability tokens zeroed out and remaining probabilities rescaled.\n",
        "    \"\"\"\n",
        "    assert len(model_logits.shape) == 3\n",
        "    probs = torch.nn.functional.softmax(model_logits / t, dim=-1)\n",
        "    batch_size, seq_len, vocab_size = probs.shape\n",
        "    probs_flat = probs.view(-1, vocab_size)\n",
        "\n",
        "    sorted_probs, sorted_indices = torch.sort(probs_flat, descending=True)\n",
        "    cumulative_probs = torch.cumsum(sorted_probs, dim=-1)\n",
        "    indices_to_remove = cumulative_probs > top_p\n",
        "    indices_to_remove[..., 1:] = indices_to_remove[..., :-1].clone()\n",
        "    indices_to_remove[..., 0] = False\n",
        "    # Set probabilities of removed tokens to 0\n",
        "    filtered_probs = sorted_probs.clone()\n",
        "    filtered_probs[indices_to_remove] = 0.0\n",
        "    # Re-normalize the probabilities of the remaining tokens\n",
        "    sum_filtered_probs = filtered_probs.sum(dim=-1, keepdim=True)\n",
        "    normalized_probs = torch.where(sum_filtered_probs == 0, torch.zeros_like(filtered_probs), filtered_probs / sum_filtered_probs)\n",
        "    # Scatter the re-normalized probabilities back to their original positions\n",
        "    result_flat = torch.zeros_like(probs_flat)\n",
        "    result_flat.scatter_(-1, sorted_indices, normalized_probs)\n",
        "    return result_flat.view(batch_size, seq_len, vocab_size)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def token_choice_adv(\n",
        "    model_logits: torch.Tensor, top_p: float, t: float\n",
        ") -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Select next token using temperature and top-p sampling.\n",
        "\n",
        "    Args:\n",
        "        model_logits: Logits of shape [batch, seq_len, vocab_size].\n",
        "        top_p: Nucleus sampling threshold.\n",
        "        t: Temperature.\n",
        "\n",
        "    Returns:\n",
        "        Selected token indices of shape [batch, 1].\n",
        "    \"\"\"\n",
        "    # This function should only operate on the last token's logits for next token prediction.\n",
        "    # Therefore, the slice [:, -1:, :] is appropriate here.\n",
        "    probs = get_dist_after_with_temp_and_topp(\n",
        "        model_logits=model_logits[:, -1:, :], top_p=top_p, t=t\n",
        "    )\n",
        "    dist = torch.distributions.Categorical(probs=probs)\n",
        "    return dist.sample()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing ###"
      ],
      "metadata": {
        "id": "U3ckp4sI5JfA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#inpucior = input('Provide the index of the first word: ')\n",
        "#inpucior = torch.tensor([[int(inpucior)]])\n",
        "inpucior = torch.tensor([[3, 15, 5]])\n",
        "output = generate(CutieSimp, inpucior, 40, token_choice = functools.partial(token_choice_adv, top_p=0.6, t=1))\n",
        "\n",
        "decoded_input = decode(inpucior, dataset.itos)\n",
        "decoded_output = decode(output, dataset.itos)\n",
        "print('-----------------')\n",
        "print('Input: ' + decoded_input)\n",
        "print('-----------------')\n",
        "print('Output: ' + decoded_output)\n",
        "print('-----------------')\n",
        "print('Message together: ')\n",
        "print('-----------------')\n",
        "print(decoded_input + ' ' + decoded_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyqgMC5XOZCm",
        "outputId": "fb8f3f70-53dc-40dd-a176-a504a6dfbd13"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------\n",
            "Input: Cutie and Farfocl\n",
            "-----------------\n",
            "Output: are  wholesome and  a lovely couple .\n",
            " Cutie is not only very very petite but also extremely smart .\n",
            " Cutie is not only really wholesome but also very very pretty .\n",
            "-----------------\n",
            "Message together: \n",
            "-----------------\n",
            "Cutie and Farfocl are  wholesome and  a lovely couple .\n",
            " Cutie is not only very very petite but also extremely smart .\n",
            " Cutie is not only really wholesome but also very very pretty .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second Dataset: TinyStories ##\n",
        "----------------------------\n",
        "Time for some storytelling! Let's whether I will be able to train a sensible model on colab free-plan GPU. \\\n",
        "Tiny stories is a well-known dataset containing short and simple stories. Language is simple which means that grammar and vocabulary are very basic. Because of that there is a hope that the model will be able to learn it and maybe create at least merely sensible stories"
      ],
      "metadata": {
        "id": "aZR20Fky7OJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Installments (colab)\n",
        "!pip install -q datasets transformers sentencepiece"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xoe8uHla7ZMs"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset Loading\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"roneneldan/TinyStories\")\n",
        "\n",
        "print(dataset)\n",
        "\n",
        "dataset_small = dataset[\"train\"].shuffle(seed=42).select(range(50000))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570,
          "referenced_widgets": [
            "6f55157455214fb5985c398bfaf40901",
            "2aabecbf318b425381fc6ef5073a05c3",
            "67f3691e143a4420ad932dcc797c5634",
            "71132327e2814266b476534a4548dc50",
            "c93ae83950fe4ce1b54aee4ecca146a6",
            "a57ba3e32f8f470aa638142d262ce218",
            "65b30d739e404edea41e6204298af9df",
            "f680e34d5b1243dfa33bcedcf10c3c6f",
            "dfc39b4da3454b0ebad024f7da76a119",
            "d5d1f86b6f9e4ffeb14e16bc8d7c5638",
            "bb0d15793ca743fea24f9dbb67c73d28",
            "11619cde6d29402582a58e782bc610a2",
            "a08c4a3e16e24d9ca752f1468e095a02",
            "c8337cc731f54a109ef34d0881c3af10",
            "b34d7a8f97ab46879c3038883b787733",
            "856699ff5aef48e59c8cc4015ddd0dfc",
            "fa7e0db792b64d13b506ab3c7e1d8728",
            "202edf57f733417fae906f22a8345e32",
            "1ee14f5518cf4805b1bb13cb74339901",
            "66bb530b53754a5193b35b1839bd51c8",
            "d3a70b5ca79245ac83b3ab2c8251f698",
            "4fd9eff68bd14273a12221f0797c0295",
            "aee7519517e94735a2fe202d1b2597d3",
            "c0eb04933f4c473c85a56a256045d76c",
            "ceeb5313d85c4d31b2646b7811ba16fe",
            "fe2890066cc94949994ae6bd52995c17",
            "2416ce16916e4ac39392945c3acd1b28",
            "975d5620020543f2945b63465722a545",
            "89f0404b68f0405db96427d0465a24c3",
            "5854d93765ee4862b856e7d918000da5",
            "d5b6591505314138a58d2df0c9629013",
            "59b92debf4db4491bb8e81519e734819",
            "aeb5c97edd8c4076b39beeea0b4a84d9",
            "f06cb65a57de45d8bb11d6efce958368",
            "9bfbbfb4340749b9800da50eac03cf92",
            "010a5b83c5c747adb4bcdb2d6f124b64",
            "de954be266aa480e8edbde1c6a7d4107",
            "a85040b03dfc470fabcc4d151bff4664",
            "109791236db341419208535ab10c886e",
            "b5396fc751c04a09b3ceaa14c92887f4",
            "45e5ea26fcb5490b82d27f995ee6e838",
            "606e7e7eb90b410ea25aa30ba669871a",
            "fda861ae95ad4d04be6b07a028b95939",
            "5fad13c9e1a04d1bbc5abdc82c17e957",
            "34802744864a4bf3b45e1a75f535ab44",
            "c4e6685e5bdd4ddc94e430304b80ba2c",
            "b6c0545896ef42ed998bfe867a793ada",
            "ed998cca1e1b467dabb67e69d7f4c0c4",
            "4bde749ee0624749862a9806496b2bc1",
            "c7bd35877f604171a889f8b0c6b1ea32",
            "df72681a5ef14c2aa423c905db4b6d7d",
            "250e07ecf587424aa2eda3c86b0845f5",
            "93c4c6cd803e4ef385cb7fc694ea65b2",
            "55acbc580e7149d1820fe12892b77d01",
            "4977ef142cbe40d0af06e356586e8f82",
            "36aecad2099c4a12a626c85ad530adf0",
            "7b33139582fe4a84af967277388a9884",
            "a46e0579425544aaa335f17c41b532a9",
            "130c9a654e964de19bacaee411b738b3",
            "a462d7eb46314838b1807ac30917912c",
            "7c7f34cfd9b44c8881c83770b7acb51e",
            "d31d6977c895436f9191514c0392e037",
            "8304a0eaf9174022955ac023d8e2847f",
            "6bf525d141734f13b76333f62f52f6d0",
            "fcca89b4ee2e4910b5cf54659a64240a",
            "4273095f9f0b486589d6d6ad43ac5c29",
            "192b02c7c285438784cc4f583836ce02",
            "4659ed11ec3d481eb530d8e9d941b8fd",
            "2fefa5bb53d64010a1be0020c2705598",
            "f6232eb5840f43b6a65a1e450d6c6e50",
            "a149dc4ac24a422487012850861b5a3b",
            "36658ae293104c4e88cab0ba7e4088b7",
            "23efc1bb7cf648868a25c26d07579a7b",
            "6157653d65d74e62a091f0a9d5749952",
            "272cb24dbd3a4fb8bbcd1a9285c9c4c4",
            "e9fa24a0eda94346974937975c2f6ced",
            "af8bc922db884019a20d8b5a53270b61",
            "817c73abe18746df9b5a67e8fc3c1146",
            "90b44cc0028d48c08743652b5d7edff8",
            "aaae903e1d364e9a837b66f97275941d",
            "b5d3522ddb2744749a372c3afbed8633",
            "4fa5a6342b3246a59c36ee8490311c10",
            "f9ed63bbf955468ebf2597c497f6c7dd",
            "63a899c7d9dd45fb85146fd803c359cc",
            "4685da701bb44ef38450af8b4049662d",
            "10cc11c6a4c74457a1bb2390a6158bee",
            "6492a2843b214f41962442051bf17a66",
            "134fe07c39784aff871289e6c7f5a923"
          ]
        },
        "id": "AhTse4w07o54",
        "outputId": "9fd0e33f-a1ec-411f-f881-5b5031190b8a",
        "cellView": "form",
        "collapsed": true
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f55157455214fb5985c398bfaf40901"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00004-2d5a1467fff108(â¦):   0%|          | 0.00/249M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "11619cde6d29402582a58e782bc610a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00001-of-00004-5852b56a2bd28f(â¦):   0%|          | 0.00/248M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aee7519517e94735a2fe202d1b2597d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00002-of-00004-a26307300439e9(â¦):   0%|          | 0.00/246M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f06cb65a57de45d8bb11d6efce958368"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00003-of-00004-d243063613e5a0(â¦):   0%|          | 0.00/248M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34802744864a4bf3b45e1a75f535ab44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/validation-00000-of-00001-869c898b5(â¦):   0%|          | 0.00/9.99M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36aecad2099c4a12a626c85ad530adf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/2119719 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "192b02c7c285438784cc4f583836ce02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/21990 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "817c73abe18746df9b5a67e8fc3c1146"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 2119719\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text'],\n",
            "        num_rows: 21990\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizer definition ###"
      ],
      "metadata": {
        "id": "Qt886fKf8V6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "\n",
        "MAX_LEN = 128 # Define MAX_LEN here\n",
        "\n",
        "tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
        "tokenizer.pre_tokenizer = Whitespace()\n",
        "\n",
        "trainer = BpeTrainer(\n",
        "    vocab_size=8000,\n",
        "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[BOS]\", \"[EOS]\"]\n",
        ")\n",
        "\n",
        "tokenizer.train_from_iterator(\n",
        "    (x[\"text\"] for x in dataset_small),\n",
        "    trainer=trainer\n",
        ")\n",
        "\n",
        "# Configure truncation on the tokenizer object\n",
        "tokenizer.enable_truncation(max_length=MAX_LEN + 1)\n",
        "# Configure padding on the tokenizer object\n",
        "tokenizer.pad_token = \"[PAD]\"\n",
        "tokenizer.enable_padding(direction=\"right\", pad_id=tokenizer.token_to_id(\"[PAD]\"), pad_type_id=0, length=MAX_LEN + 1)\n",
        "\n",
        "def tokenize(example):\n",
        "    # When batched=True, example[\"text\"] will be a list of strings\n",
        "    # We use encode_batch for efficiency, truncation and padding are configured globally\n",
        "    encodings = tokenizer.encode_batch(\n",
        "        example[\"text\"],\n",
        "        add_special_tokens=True\n",
        "    )\n",
        "\n",
        "    # Prepare lists for x and y sequences\n",
        "    xs_batch = []\n",
        "    ys_batch = []\n",
        "\n",
        "    for encoding in encodings:\n",
        "        tokens = encoding.ids\n",
        "        # Since truncation and padding are enabled, `tokens` will be of length MAX_LEN + 1.\n",
        "        x = tokens[:-1]  # Input sequence of length MAX_LEN\n",
        "        y = tokens[1:]   # Target sequence of length MAX_LEN\n",
        "\n",
        "        # Explicitly convert to torch.Tensor\n",
        "        xs_batch.append(torch.tensor(x, dtype=torch.long))\n",
        "        ys_batch.append(torch.tensor(y, dtype=torch.long))\n",
        "\n",
        "    # The map function expects a dictionary of lists for batching\n",
        "    return {\"x\": xs_batch, \"y\": ys_batch}\n",
        "\n",
        "def collate_fn(batch):\n",
        "    x = torch.stack([item[\"x\"] for item in batch])\n",
        "    y = torch.stack([item[\"y\"] for item in batch])\n",
        "    # Move to device within the collate_fn\n",
        "    return x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "tokenized_ds = dataset_small.map(\n",
        "    tokenize,\n",
        "    batched=True,\n",
        "    remove_columns=[\"text\"],\n",
        "    num_proc=2 # Use multiple processes for faster tokenization\n",
        ")\n",
        "\n",
        "# Split the tokenized dataset into training and validation sets\n",
        "split_ds = tokenized_ds.train_test_split(test_size=0.1, seed=42) # 10% for validation\n",
        "\n",
        "train_ds = split_ds[\"train\"]\n",
        "val_ds = split_ds[\"test\"]\n",
        "\n",
        "# Set the format for PyTorch, specifying the columns\n",
        "train_ds.set_format(type=\"torch\", columns=[\"x\", \"y\"])\n",
        "val_ds.set_format(type=\"torch\", columns=[\"x\", \"y\"])\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=32,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "def train(\n",
        "    model: torch.nn.Module,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    dataloader: torch.utils.data.DataLoader,\n",
        "    eval_fn: functools.partial,\n",
        "    num_epochs: int,\n",
        "    scheduler,\n",
        "):\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        if epoch == 0:\n",
        "            eval_fn(epoch, model)\n",
        "\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        num_batches = 0\n",
        "        for i, (x, y) in tqdm(enumerate(dataloader)):\n",
        "            ### My code ###\n",
        "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "            model_out = model(x)\n",
        "            #loss = torch.nn.functional.cross_entropy(model_out.transpose(1, 2), y)\n",
        "            loss = torch.nn.functional.cross_entropy(model_out.transpose(1, 2), y, ignore_index=tokenizer.token_to_id(\"[PAD]\"))  # <- ignore padding\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            if i > 100:\n",
        "                break\n",
        "\n",
        "        eval_fn(epoch, model)"
      ],
      "metadata": {
        "id": "It-u7eb08UFq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ae077befbaf24db78088d3e9874cd7e2",
            "4c6f8ddef41444c49319ab84ad78fe6e",
            "cca51b8a46824ea0812447fdf1faa41f",
            "942572395e4942ec9cf7c841c7b75996",
            "b5667210da904939bf366052899cc35c",
            "566fa27734e842acbe794186b8980e0f",
            "6b242525c66a47709d31df16403b35f1",
            "fd7f70e5a9e94bfea12650e8d9de326b",
            "43250adbe6e742c2b3ba08c22d9d85b7",
            "4eb09f94855b4980934bfee234a50baa",
            "89fe2ed75a09434e91a7a7f012ce5c73"
          ]
        },
        "outputId": "2979cd99-6385-4ce3-c6a2-9068c8825d09"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae077befbaf24db78088d3e9874cd7e2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sanity check\n",
        "print(tokenizer.decode(tokenized_ds[0][\"x\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAPg5ozw8YT1",
        "outputId": "d022ec71-614a-411e-ce66-f094ab1a90ff"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tim and Mia like to play in the park . They see a big club on the ground . It is brown and long and heavy . \" Look , a club !\" Tim says . \" I can lift it !\" He tries to lift the club , but it is too tough . He falls down and drops the club . \" Ouch !\" he says . \" That hurt !\" Mia laughs . She is not mean , she just thinks it is funny . \" Let me try !\" she says . \" I can balance it !\" She picks up the club and puts it on her head . She walks slowly and carefully . She does not fall down . \" Wow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model definition ###"
      ],
      "metadata": {
        "id": "t5IJW0dHIGMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TinyStoryTeller = Transformer(\n",
        "    vocab_size=8000,          # or tokenizer.vocab_size\n",
        "    n_layers=4,\n",
        "    hidden_dim=256,\n",
        "    ff_dim=1024,\n",
        "    num_heads=4,\n",
        "    head_dim=64,\n",
        "\n",
        "    use_sliding_window_alternating=False,\n",
        "    use_moe=False,\n",
        ")"
      ],
      "metadata": {
        "id": "gREHMyCm-oUY"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training ###"
      ],
      "metadata": {
        "id": "ppBoII6FIKpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "TinyStoryTeller.to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(TinyStoryTeller.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs  = 16\n",
        "\n",
        "scheduler = CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=100 * num_epochs\n",
        ")\n",
        "\n",
        "train(\n",
        "    model=TinyStoryTeller,\n",
        "    optimizer=optimizer,\n",
        "    dataloader=train_loader,\n",
        "    eval_fn=functools.partial(\n",
        "        eval_fn,\n",
        "        dataloader=val_loader,\n",
        "    ),\n",
        "    num_epochs=num_epochs, scheduler=scheduler\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQRT-IaU-0sS",
        "outputId": "e1c3cd46-e80c-46ff-a053-b13aeded30c0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Avg eval accuracy 4.069010537932627e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:20,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Avg eval accuracy 0.326904296875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:21,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Avg eval accuracy 0.3718668818473816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:15,  1.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2: Avg eval accuracy 0.3967488706111908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:10,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3: Avg eval accuracy 0.4120686948299408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:10,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4: Avg eval accuracy 0.4230550229549408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:14,  1.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5: Avg eval accuracy 0.43450927734375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:21,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6: Avg eval accuracy 0.4443562924861908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:19,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7: Avg eval accuracy 0.45098876953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:19,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8: Avg eval accuracy 0.4582112729549408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:08,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9: Avg eval accuracy 0.4644775390625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:08,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10: Avg eval accuracy 0.4677937924861908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:07,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11: Avg eval accuracy 0.4700520932674408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:07,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12: Avg eval accuracy 0.4732666015625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:07,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13: Avg eval accuracy 0.4757893979549408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:06,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14: Avg eval accuracy 0.4761556088924408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:06,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15: Avg eval accuracy 0.47625732421875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Text generating function\n",
        "@torch.no_grad()\n",
        "def generate_text(model, tokenizer, prompt=\"\", max_len=128, temperature=0.2, top_k=50):\n",
        "    model.eval()\n",
        "\n",
        "    input_ids = torch.tensor([tokenizer.encode(prompt).ids], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        logits = model(input_ids)                 # [1, seq_len, vocab_size]\n",
        "        next_token_logits = logits[:, -1, :] / temperature\n",
        "\n",
        "        # Top-k sampling\n",
        "        topk_probs, topk_indices = torch.topk(next_token_logits, k=top_k, dim=-1)  # [1, k]\n",
        "        probs = torch.nn.functional.softmax(topk_probs, dim=-1)                     # [1, k]\n",
        "\n",
        "        # Sample 1 token\n",
        "        next_token_idx_in_topk = torch.multinomial(probs, num_samples=1)           # [1,1]\n",
        "        next_token = topk_indices.gather(-1, next_token_idx_in_topk)               # [1,1]\n",
        "        # Append token\n",
        "        input_ids = torch.cat([input_ids, next_token], dim=1)                       # [1, seq_len+1]\n",
        "\n",
        "    return tokenizer.decode(input_ids[0].tolist())"
      ],
      "metadata": {
        "id": "FjcCQlvmF9Vx",
        "cellView": "form"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompting and short discussion ###"
      ],
      "metadata": {
        "id": "0bGwrkWKIfOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"He\"\n",
        "story = generate_text(TinyStoryTeller, tokenizer, prompt=prompt, max_len=24, temperature=1., top_k=50)\n",
        "print(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgzWZ4efGL8_",
        "outputId": "8f010920-3e53-41d6-e5b4-3aaec8055074"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He and Tom has a big bag . Tom and Tom are very pretty and had a big head . One day , a big\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"He\"\n",
        "story = generate_text(TinyStoryTeller, tokenizer, prompt=prompt, max_len=24, temperature=0.1, top_k=50)\n",
        "print(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a1JheDlkdiK",
        "outputId": "9b26c32a-f5fb-4510-9ddd-618d187a26c2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He and a hat . She liked to make a big hat . She was very happy . She wanted to make a big cake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here the results are unfortunately pretty unimpressive. It seems that my TinyStoriesTeller is to small so his stories are quite incoherent. Unfortunately, I don't have computational resources to train a better model. Still the model learns *something* as accuracy is around 48%. \\\n",
        "The stories generated by it doesn't make much sense but one can see some line of reasoning there (especially locally).\n",
        "As one can see lower temperature seem to be helping (which makes sense as the model probably has a pretty narrow tree of reasoning) \\\n",
        "In the next section I will try to train a slightly bigger model"
      ],
      "metadata": {
        "id": "BvL9BQgGlTSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second attempt, a slightly bigger model ###"
      ],
      "metadata": {
        "id": "clAEECkLIyH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "InfinitesimallyBiggerTinyStoryTeller = Transformer(\n",
        "    vocab_size=8000,          # or tokenizer.vocab_size\n",
        "    n_layers=6,\n",
        "    hidden_dim=256,\n",
        "    ff_dim=712,\n",
        "    num_heads=6,\n",
        "    head_dim=64,\n",
        "\n",
        "    use_sliding_window_alternating=True,\n",
        "    window_size=32,\n",
        "    use_moe=False,\n",
        ")"
      ],
      "metadata": {
        "id": "QRTvudi8nb8g"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Training again...\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "InfinitesimallyBiggerTinyStoryTeller.to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(InfinitesimallyBiggerTinyStoryTeller.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs  = 16\n",
        "\n",
        "scheduler = CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=100 * num_epochs\n",
        ")\n",
        "\n",
        "train(\n",
        "    model=InfinitesimallyBiggerTinyStoryTeller,\n",
        "    optimizer=optimizer,\n",
        "    dataloader=train_loader,\n",
        "    eval_fn=functools.partial(\n",
        "        eval_fn,\n",
        "        dataloader=val_loader,\n",
        "    ),\n",
        "    num_epochs=num_epochs, scheduler=scheduler\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VrX2qe4npDx_",
        "outputId": "12289395-7061-4686-a029-958abe44089d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Avg eval accuracy 4.069010537932627e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:54,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Avg eval accuracy 0.3417765498161316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:51,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Avg eval accuracy 0.3836466670036316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:50,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2: Avg eval accuracy 0.4070231318473816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:51,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3: Avg eval accuracy 0.42205810546875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:51,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4: Avg eval accuracy 0.4333903193473816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:50,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5: Avg eval accuracy 0.4451497495174408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:49,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6: Avg eval accuracy 0.453125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:49,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7: Avg eval accuracy 0.4587809443473816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:50,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8: Avg eval accuracy 0.467041015625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:50,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9: Avg eval accuracy 0.47216796875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:50,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10: Avg eval accuracy 0.47723388671875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:49,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11: Avg eval accuracy 0.48223876953125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:50,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12: Avg eval accuracy 0.4851277768611908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:49,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13: Avg eval accuracy 0.4874267578125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:48,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14: Avg eval accuracy 0.4879353940486908\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:47,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15: Avg eval accuracy 0.4879150390625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"He\"\n",
        "story = generate_text(TinyStoryTeller, tokenizer, prompt=prompt, max_len=24, temperature=1., top_k=50)\n",
        "print(story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OSih6RUxNw3",
        "outputId": "078aad7c-b2c1-4404-b38a-9bf4f036fe50"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He and a yellow kite . It was loud and pretty and round the hat and a shiny blue hat . It had white hair\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results are still not great..."
      ],
      "metadata": {
        "id": "shuZJ1y_D64Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Third Dataset: Mickiewicz's poetry ####\n",
        "Adam Mickiewicz is a national poet of Poland, Lithuania and Belarus. His works were so important for Polish culture that he is known as 'National Prophet'. Because of that I wanted to see what such a small GPT model could learn from his works (spoiler: not much). Fortunately, books of Mickiewicz ('GraÅ¼yna', 'Dziady', 'Pan Tadeusz' and 'Konrad Wallenrod') are easy to download in txt format (from wolnelektury.pl for instance)."
      ],
      "metadata": {
        "id": "porQuuM2ECtz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data loading and processing ###"
      ],
      "metadata": {
        "id": "YvGUnIFGGtJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt_files = ['Pan_Tadeusz.txt', 'Wallenrod.txt', 'grazyna.txt', 'dziady.txt']\n",
        "texts = []\n",
        "for f in txt_files:\n",
        "    with open(f, \"r\", encoding=\"utf-8\") as file:\n",
        "        texts.append(file.read())\n",
        "\n",
        "# Combine into one large string if desired\n",
        "full_text = \"\\n\".join(texts)"
      ],
      "metadata": {
        "id": "fGnRoFOqyuBb"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# Replace multiple spaces with single space\n",
        "clean_text = re.sub(r\"[ \\t]+\", \" \", full_text)\n",
        "\n",
        "# Keep line breaks for poetry, but normalize Windows/Mac line endings\n",
        "clean_text = clean_text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
        "\n",
        "# Remove non-printable characters\n",
        "clean_text = re.sub(r\"[^\\x20-\\x7EÄÄÄÅÅÃ³ÅÅºÅ¼ÄÄÄÅÅÃÅÅ¹Å»;:â\\n-]\", \"\", clean_text)\n",
        "\n",
        "# Remove words written in all caps (length >= 3)\n",
        "clean_text = re.sub(r\"\\b[A-ZÄÄÄÅÅÃÅÅ¹Å»]{3,}\\b\", \"\", clean_text)\n",
        "clean_text = re.sub(r\"[ \\t]+\", \" \", clean_text)\n",
        "clean_text = re.sub(r\"\\n\\s*\\n\", \"\\n\", clean_text)  # remove multiple blank lines"
      ],
      "metadata": {
        "id": "ZAgtMUhfzEn0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_chars = 512  # approximate max length per sequence\n",
        "lines = clean_text.split(\"\\n\")\n",
        "chunks = []\n",
        "current_chunk = \"\"\n",
        "for line in lines:\n",
        "    line = line.strip()\n",
        "    if not line:  # skip empty lines\n",
        "        continue\n",
        "\n",
        "    # if adding the line exceeds max_chars\n",
        "    if len(current_chunk) + len(line) + 1 > max_chars:\n",
        "        if current_chunk:           # only append non-empty chunk\n",
        "            chunks.append(current_chunk)\n",
        "        current_chunk = line + \"\\n\"  # start new chunk with current line\n",
        "    else:\n",
        "        current_chunk += line + \"\\n\"  # add line to current chunk\n",
        "\n",
        "# append any leftover chunk\n",
        "if current_chunk:\n",
        "    chunks.append(current_chunk)\n",
        "\n",
        "print(\"Number of chunks:\", len(chunks))\n",
        "print(chunks[1][:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0o2yz98OzHuO",
        "outputId": "8c66ec8d-c36d-4bb3-d4ae-d36f84d0c100"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 1320\n",
            "IÅÄ za wrÃ³cone Å¼ycie podziÄkowaÄ Bogu),\n",
            "Tak nas powrÃ³cisz cudem na Ojczyzny Åono.\n",
            "Tymczasem przenoÅ mojÄ duszÄ utÄsknionÄ\n",
            "Do tych pagÃ³rkÃ³w leÅnych, do tych ÅÄk zielonych,\n",
            "Szeroko nad bÅÄkitnym Niemnem\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
        "\n",
        "# Initialize a Byte-Pair Encoding (BPE) tokenizer\n",
        "tokenizer = Tokenizer(models.BPE())\n",
        "#tokenizer.pre_tokenizer = pre_tokenizers.Whitespace()  # tokenizes on whitespace\n",
        "\n",
        "# Train tokenizer on your text chunks\n",
        "trainer = trainers.BpeTrainer(\n",
        "    vocab_size=8000,  # can adjust depending on dataset size\n",
        "    min_frequency=2,\n",
        "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        ")\n",
        "tokenizer.train_from_iterator(chunks, trainer)"
      ],
      "metadata": {
        "id": "H8ls-eJizJGi"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "for chunk in chunks:\n",
        "    ids = tokenizer.encode(chunk).ids\n",
        "    input_ids.append(ids)\n",
        "\n",
        "# Optional: pad sequences to same length for batch training\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Filter out empty tokenized lists before converting to tensors\n",
        "input_ids = [torch.tensor(ids, dtype=torch.long) for ids in input_ids if ids]\n",
        "padded_inputs = pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.token_to_id(\"[PAD]\"))"
      ],
      "metadata": {
        "id": "foRKx5bAzO56"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "\n",
        "# Shift inputs by one for causal LM\n",
        "x = padded_inputs[:, :-1]\n",
        "y = padded_inputs[:, 1:]\n",
        "\n",
        "# Create a TensorDataset from x and y for WieszczMimic\n",
        "full_wieszcz_dataset = TensorDataset(x, y)\n",
        "\n",
        "val_size = int(0.1 * len(full_wieszcz_dataset))\n",
        "train_size = len(full_wieszcz_dataset) - val_size\n",
        "\n",
        "train_subset, val_subset = random_split(full_wieszcz_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=8, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=8)"
      ],
      "metadata": {
        "id": "NwSAv7_70AOE"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model definition ###"
      ],
      "metadata": {
        "id": "7tMtoqW_Gz6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WieszczMimic = Transformer(\n",
        "    vocab_size=8000,          # or tokenizer.vocab_size\n",
        "    n_layers=4,\n",
        "    hidden_dim=256,\n",
        "    ff_dim=712,\n",
        "    num_heads=4,\n",
        "    head_dim=64,\n",
        "\n",
        "    use_sliding_window_alternating=False,\n",
        "    use_moe=False,\n",
        ")"
      ],
      "metadata": {
        "id": "Z__sGmVWzQty"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model training ###"
      ],
      "metadata": {
        "id": "ce0LCCLDG5m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "WieszczMimic.to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(WieszczMimic.parameters(), lr=0.0003)\n",
        "\n",
        "num_epochs  = 16\n",
        "\n",
        "scheduler = CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=100 * num_epochs\n",
        ")\n",
        "\n",
        "# Define a wrapper for eval_fn that matches the signature expected by the `train` function\n",
        "def _eval_fn_for_train_call(epoch, model_instance):\n",
        "    # The eval_fn from pLlSYPoogUBq expects (step, model, dataloader)\n",
        "    # The train function from It-u7eb08UFq calls eval_fn(epoch, model)\n",
        "    # This wrapper aligns those two calls.\n",
        "    acc = eval_fn(\n",
        "        epoch,\n",
        "        model_instance,\n",
        "        val_loader\n",
        "    )\n",
        "    print(f\"{epoch}: Avg eval accuracy {acc}\")\n",
        "\n",
        "train(\n",
        "    model=WieszczMimic,\n",
        "    optimizer=optimizer,\n",
        "    dataloader=train_loader,\n",
        "    eval_fn=_eval_fn_for_train_call, # Pass the wrapper function\n",
        "    num_epochs=num_epochs, scheduler=scheduler\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU0_bisVz0oO",
        "outputId": "dbc9d809-1737-438e-aead-0be6d3971682"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Avg eval accuracy 0.0\n",
            "0: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:25,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: Avg eval accuracy 0.004179526586085558\n",
            "0: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:24,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: Avg eval accuracy 0.0030221191700547934\n",
            "1: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:25,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2: Avg eval accuracy 0.005401234608143568\n",
            "2: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:25,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3: Avg eval accuracy 0.009645061567425728\n",
            "3: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:25,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4: Avg eval accuracy 0.015046295709908009\n",
            "4: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:24,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5: Avg eval accuracy 0.01845421828329563\n",
            "5: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:23,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6: Avg eval accuracy 0.022633744403719902\n",
            "6: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:24,  1.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7: Avg eval accuracy 0.023148147389292717\n",
            "7: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:25,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8: Avg eval accuracy 0.023083847016096115\n",
            "8: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:28,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9: Avg eval accuracy 0.023726850748062134\n",
            "9: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:30,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10: Avg eval accuracy 0.024884259328246117\n",
            "10: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:30,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11: Avg eval accuracy 0.025527263060212135\n",
            "11: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:30,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12: Avg eval accuracy 0.023791151121258736\n",
            "12: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:30,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13: Avg eval accuracy 0.02359825000166893\n",
            "13: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:29,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14: Avg eval accuracy 0.02462705597281456\n",
            "14: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:30,  1.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15: Avg eval accuracy 0.02391975186765194\n",
            "15: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:34,  1.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16: Avg eval accuracy 0.02289094589650631\n",
            "16: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:29,  1.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17: Avg eval accuracy 0.02327674813568592\n",
            "17: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:27,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18: Avg eval accuracy 0.023019546642899513\n",
            "18: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:27,  1.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19: Avg eval accuracy 0.02289094589650631\n",
            "19: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:27,  1.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20: Avg eval accuracy 0.02289094589650631\n",
            "20: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:26,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21: Avg eval accuracy 0.02289094589650631\n",
            "21: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:26,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22: Avg eval accuracy 0.022826645523309708\n",
            "22: Avg eval accuracy None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "101it [01:25,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23: Avg eval accuracy 0.022826645523309708\n",
            "23: Avg eval accuracy None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompting and testing"
      ],
      "metadata": {
        "id": "-hT8qMN0G978"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\"Litwo!\", '\\nGdzie', '\\nI']\n",
        "for prompt in prompts:\n",
        "  print('-------------------------------------')\n",
        "  story = generate_text(WieszczMimic, tokenizer, prompt=prompt, max_len=24, temperature=1., top_k=50)\n",
        "  print(story)\n",
        "  print('-------------------------------------')"
      ],
      "metadata": {
        "id": "C3YrSkhU6C3a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Y2mt5ZJIgUBm",
        "HCDtN5qHgUBn",
        "blCnnxtigUBn",
        "2AOdAri4gUBo",
        "eh3imyNiz--N",
        "G1SB2DRlgUBr"
      ]
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6f55157455214fb5985c398bfaf40901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2aabecbf318b425381fc6ef5073a05c3",
              "IPY_MODEL_67f3691e143a4420ad932dcc797c5634",
              "IPY_MODEL_71132327e2814266b476534a4548dc50"
            ],
            "layout": "IPY_MODEL_c93ae83950fe4ce1b54aee4ecca146a6"
          }
        },
        "2aabecbf318b425381fc6ef5073a05c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a57ba3e32f8f470aa638142d262ce218",
            "placeholder": "â",
            "style": "IPY_MODEL_65b30d739e404edea41e6204298af9df",
            "value": "README.md:â"
          }
        },
        "67f3691e143a4420ad932dcc797c5634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f680e34d5b1243dfa33bcedcf10c3c6f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dfc39b4da3454b0ebad024f7da76a119",
            "value": 1
          }
        },
        "71132327e2814266b476534a4548dc50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5d1f86b6f9e4ffeb14e16bc8d7c5638",
            "placeholder": "â",
            "style": "IPY_MODEL_bb0d15793ca743fea24f9dbb67c73d28",
            "value": "â1.06k/?â[00:00&lt;00:00,â105kB/s]"
          }
        },
        "c93ae83950fe4ce1b54aee4ecca146a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a57ba3e32f8f470aa638142d262ce218": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65b30d739e404edea41e6204298af9df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f680e34d5b1243dfa33bcedcf10c3c6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "dfc39b4da3454b0ebad024f7da76a119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5d1f86b6f9e4ffeb14e16bc8d7c5638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb0d15793ca743fea24f9dbb67c73d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "11619cde6d29402582a58e782bc610a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a08c4a3e16e24d9ca752f1468e095a02",
              "IPY_MODEL_c8337cc731f54a109ef34d0881c3af10",
              "IPY_MODEL_b34d7a8f97ab46879c3038883b787733"
            ],
            "layout": "IPY_MODEL_856699ff5aef48e59c8cc4015ddd0dfc"
          }
        },
        "a08c4a3e16e24d9ca752f1468e095a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa7e0db792b64d13b506ab3c7e1d8728",
            "placeholder": "â",
            "style": "IPY_MODEL_202edf57f733417fae906f22a8345e32",
            "value": "data/train-00000-of-00004-2d5a1467fff108(â¦):â100%"
          }
        },
        "c8337cc731f54a109ef34d0881c3af10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ee14f5518cf4805b1bb13cb74339901",
            "max": 248731111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66bb530b53754a5193b35b1839bd51c8",
            "value": 248731111
          }
        },
        "b34d7a8f97ab46879c3038883b787733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3a70b5ca79245ac83b3ab2c8251f698",
            "placeholder": "â",
            "style": "IPY_MODEL_4fd9eff68bd14273a12221f0797c0295",
            "value": "â249M/249Mâ[00:03&lt;00:00,â216MB/s]"
          }
        },
        "856699ff5aef48e59c8cc4015ddd0dfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa7e0db792b64d13b506ab3c7e1d8728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "202edf57f733417fae906f22a8345e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ee14f5518cf4805b1bb13cb74339901": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66bb530b53754a5193b35b1839bd51c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3a70b5ca79245ac83b3ab2c8251f698": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd9eff68bd14273a12221f0797c0295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aee7519517e94735a2fe202d1b2597d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0eb04933f4c473c85a56a256045d76c",
              "IPY_MODEL_ceeb5313d85c4d31b2646b7811ba16fe",
              "IPY_MODEL_fe2890066cc94949994ae6bd52995c17"
            ],
            "layout": "IPY_MODEL_2416ce16916e4ac39392945c3acd1b28"
          }
        },
        "c0eb04933f4c473c85a56a256045d76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_975d5620020543f2945b63465722a545",
            "placeholder": "â",
            "style": "IPY_MODEL_89f0404b68f0405db96427d0465a24c3",
            "value": "data/train-00001-of-00004-5852b56a2bd28f(â¦):â100%"
          }
        },
        "ceeb5313d85c4d31b2646b7811ba16fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5854d93765ee4862b856e7d918000da5",
            "max": 248171980,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5b6591505314138a58d2df0c9629013",
            "value": 248171980
          }
        },
        "fe2890066cc94949994ae6bd52995c17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59b92debf4db4491bb8e81519e734819",
            "placeholder": "â",
            "style": "IPY_MODEL_aeb5c97edd8c4076b39beeea0b4a84d9",
            "value": "â248M/248Mâ[00:01&lt;00:00,â190MB/s]"
          }
        },
        "2416ce16916e4ac39392945c3acd1b28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "975d5620020543f2945b63465722a545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89f0404b68f0405db96427d0465a24c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5854d93765ee4862b856e7d918000da5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5b6591505314138a58d2df0c9629013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "59b92debf4db4491bb8e81519e734819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aeb5c97edd8c4076b39beeea0b4a84d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f06cb65a57de45d8bb11d6efce958368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9bfbbfb4340749b9800da50eac03cf92",
              "IPY_MODEL_010a5b83c5c747adb4bcdb2d6f124b64",
              "IPY_MODEL_de954be266aa480e8edbde1c6a7d4107"
            ],
            "layout": "IPY_MODEL_a85040b03dfc470fabcc4d151bff4664"
          }
        },
        "9bfbbfb4340749b9800da50eac03cf92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_109791236db341419208535ab10c886e",
            "placeholder": "â",
            "style": "IPY_MODEL_b5396fc751c04a09b3ceaa14c92887f4",
            "value": "data/train-00002-of-00004-a26307300439e9(â¦):â100%"
          }
        },
        "010a5b83c5c747adb4bcdb2d6f124b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45e5ea26fcb5490b82d27f995ee6e838",
            "max": 245894874,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_606e7e7eb90b410ea25aa30ba669871a",
            "value": 245894874
          }
        },
        "de954be266aa480e8edbde1c6a7d4107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fda861ae95ad4d04be6b07a028b95939",
            "placeholder": "â",
            "style": "IPY_MODEL_5fad13c9e1a04d1bbc5abdc82c17e957",
            "value": "â246M/246Mâ[00:04&lt;00:00,â39.5MB/s]"
          }
        },
        "a85040b03dfc470fabcc4d151bff4664": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "109791236db341419208535ab10c886e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5396fc751c04a09b3ceaa14c92887f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45e5ea26fcb5490b82d27f995ee6e838": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "606e7e7eb90b410ea25aa30ba669871a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fda861ae95ad4d04be6b07a028b95939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fad13c9e1a04d1bbc5abdc82c17e957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34802744864a4bf3b45e1a75f535ab44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4e6685e5bdd4ddc94e430304b80ba2c",
              "IPY_MODEL_b6c0545896ef42ed998bfe867a793ada",
              "IPY_MODEL_ed998cca1e1b467dabb67e69d7f4c0c4"
            ],
            "layout": "IPY_MODEL_4bde749ee0624749862a9806496b2bc1"
          }
        },
        "c4e6685e5bdd4ddc94e430304b80ba2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7bd35877f604171a889f8b0c6b1ea32",
            "placeholder": "â",
            "style": "IPY_MODEL_df72681a5ef14c2aa423c905db4b6d7d",
            "value": "data/train-00003-of-00004-d243063613e5a0(â¦):â100%"
          }
        },
        "b6c0545896ef42ed998bfe867a793ada": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_250e07ecf587424aa2eda3c86b0845f5",
            "max": 247988350,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93c4c6cd803e4ef385cb7fc694ea65b2",
            "value": 247988350
          }
        },
        "ed998cca1e1b467dabb67e69d7f4c0c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55acbc580e7149d1820fe12892b77d01",
            "placeholder": "â",
            "style": "IPY_MODEL_4977ef142cbe40d0af06e356586e8f82",
            "value": "â248M/248Mâ[00:01&lt;00:00,â193MB/s]"
          }
        },
        "4bde749ee0624749862a9806496b2bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7bd35877f604171a889f8b0c6b1ea32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df72681a5ef14c2aa423c905db4b6d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "250e07ecf587424aa2eda3c86b0845f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93c4c6cd803e4ef385cb7fc694ea65b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55acbc580e7149d1820fe12892b77d01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4977ef142cbe40d0af06e356586e8f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36aecad2099c4a12a626c85ad530adf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b33139582fe4a84af967277388a9884",
              "IPY_MODEL_a46e0579425544aaa335f17c41b532a9",
              "IPY_MODEL_130c9a654e964de19bacaee411b738b3"
            ],
            "layout": "IPY_MODEL_a462d7eb46314838b1807ac30917912c"
          }
        },
        "7b33139582fe4a84af967277388a9884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c7f34cfd9b44c8881c83770b7acb51e",
            "placeholder": "â",
            "style": "IPY_MODEL_d31d6977c895436f9191514c0392e037",
            "value": "data/validation-00000-of-00001-869c898b5(â¦):â100%"
          }
        },
        "a46e0579425544aaa335f17c41b532a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8304a0eaf9174022955ac023d8e2847f",
            "max": 9989127,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bf525d141734f13b76333f62f52f6d0",
            "value": 9989127
          }
        },
        "130c9a654e964de19bacaee411b738b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcca89b4ee2e4910b5cf54659a64240a",
            "placeholder": "â",
            "style": "IPY_MODEL_4273095f9f0b486589d6d6ad43ac5c29",
            "value": "â9.99M/9.99Mâ[00:00&lt;00:00,â14.6MB/s]"
          }
        },
        "a462d7eb46314838b1807ac30917912c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c7f34cfd9b44c8881c83770b7acb51e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d31d6977c895436f9191514c0392e037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8304a0eaf9174022955ac023d8e2847f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bf525d141734f13b76333f62f52f6d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fcca89b4ee2e4910b5cf54659a64240a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4273095f9f0b486589d6d6ad43ac5c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "192b02c7c285438784cc4f583836ce02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4659ed11ec3d481eb530d8e9d941b8fd",
              "IPY_MODEL_2fefa5bb53d64010a1be0020c2705598",
              "IPY_MODEL_f6232eb5840f43b6a65a1e450d6c6e50"
            ],
            "layout": "IPY_MODEL_a149dc4ac24a422487012850861b5a3b"
          }
        },
        "4659ed11ec3d481eb530d8e9d941b8fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36658ae293104c4e88cab0ba7e4088b7",
            "placeholder": "â",
            "style": "IPY_MODEL_23efc1bb7cf648868a25c26d07579a7b",
            "value": "Generatingâtrainâsplit:â100%"
          }
        },
        "2fefa5bb53d64010a1be0020c2705598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6157653d65d74e62a091f0a9d5749952",
            "max": 2119719,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_272cb24dbd3a4fb8bbcd1a9285c9c4c4",
            "value": 2119719
          }
        },
        "f6232eb5840f43b6a65a1e450d6c6e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9fa24a0eda94346974937975c2f6ced",
            "placeholder": "â",
            "style": "IPY_MODEL_af8bc922db884019a20d8b5a53270b61",
            "value": "â2119719/2119719â[00:18&lt;00:00,â135233.93âexamples/s]"
          }
        },
        "a149dc4ac24a422487012850861b5a3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36658ae293104c4e88cab0ba7e4088b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23efc1bb7cf648868a25c26d07579a7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6157653d65d74e62a091f0a9d5749952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "272cb24dbd3a4fb8bbcd1a9285c9c4c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9fa24a0eda94346974937975c2f6ced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af8bc922db884019a20d8b5a53270b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "817c73abe18746df9b5a67e8fc3c1146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90b44cc0028d48c08743652b5d7edff8",
              "IPY_MODEL_aaae903e1d364e9a837b66f97275941d",
              "IPY_MODEL_b5d3522ddb2744749a372c3afbed8633"
            ],
            "layout": "IPY_MODEL_4fa5a6342b3246a59c36ee8490311c10"
          }
        },
        "90b44cc0028d48c08743652b5d7edff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9ed63bbf955468ebf2597c497f6c7dd",
            "placeholder": "â",
            "style": "IPY_MODEL_63a899c7d9dd45fb85146fd803c359cc",
            "value": "Generatingâvalidationâsplit:â100%"
          }
        },
        "aaae903e1d364e9a837b66f97275941d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4685da701bb44ef38450af8b4049662d",
            "max": 21990,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_10cc11c6a4c74457a1bb2390a6158bee",
            "value": 21990
          }
        },
        "b5d3522ddb2744749a372c3afbed8633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6492a2843b214f41962442051bf17a66",
            "placeholder": "â",
            "style": "IPY_MODEL_134fe07c39784aff871289e6c7f5a923",
            "value": "â21990/21990â[00:00&lt;00:00,â153524.72âexamples/s]"
          }
        },
        "4fa5a6342b3246a59c36ee8490311c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9ed63bbf955468ebf2597c497f6c7dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63a899c7d9dd45fb85146fd803c359cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4685da701bb44ef38450af8b4049662d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10cc11c6a4c74457a1bb2390a6158bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6492a2843b214f41962442051bf17a66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "134fe07c39784aff871289e6c7f5a923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae077befbaf24db78088d3e9874cd7e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c6f8ddef41444c49319ab84ad78fe6e",
              "IPY_MODEL_cca51b8a46824ea0812447fdf1faa41f",
              "IPY_MODEL_942572395e4942ec9cf7c841c7b75996"
            ],
            "layout": "IPY_MODEL_b5667210da904939bf366052899cc35c"
          }
        },
        "4c6f8ddef41444c49319ab84ad78fe6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_566fa27734e842acbe794186b8980e0f",
            "placeholder": "â",
            "style": "IPY_MODEL_6b242525c66a47709d31df16403b35f1",
            "value": "Mapâ(num_proc=2):â100%"
          }
        },
        "cca51b8a46824ea0812447fdf1faa41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd7f70e5a9e94bfea12650e8d9de326b",
            "max": 50000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43250adbe6e742c2b3ba08c22d9d85b7",
            "value": 50000
          }
        },
        "942572395e4942ec9cf7c841c7b75996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4eb09f94855b4980934bfee234a50baa",
            "placeholder": "â",
            "style": "IPY_MODEL_89fe2ed75a09434e91a7a7f012ce5c73",
            "value": "â50000/50000â[00:23&lt;00:00,â2430.00âexamples/s]"
          }
        },
        "b5667210da904939bf366052899cc35c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "566fa27734e842acbe794186b8980e0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b242525c66a47709d31df16403b35f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd7f70e5a9e94bfea12650e8d9de326b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43250adbe6e742c2b3ba08c22d9d85b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4eb09f94855b4980934bfee234a50baa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89fe2ed75a09434e91a7a7f012ce5c73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}